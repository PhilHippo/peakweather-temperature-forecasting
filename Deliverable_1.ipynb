{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38bcbaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsl version  : 0.9.5\n",
      "torch version: 2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/miniconda3/envs/peakweather-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tsl\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj\n",
    "\n",
    "print(f\"tsl version  : {tsl.__version__}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(edgeitems=3, precision=3)\n",
    "torch.set_printoptions(edgeitems=2, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af0462e",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22baec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utility functions ################\n",
    "def print_matrix(matrix):\n",
    "    return pd.DataFrame(matrix)\n",
    "\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)\n",
    "\n",
    "def plot_map(dataset, ei, ew, filename, th=0.0, color_factor=1.0):\n",
    "    \"\"\"\n",
    "    Plots the graph on a geographical map using Folium.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The dataset containing sensor locations.\n",
    "    - ei: Edge index (pairs of connected nodes).\n",
    "    - ew: Edge weights (used to set line thickness/color).\n",
    "    - filename: Name of the HTML file where the map will be saved.\n",
    "    - th: Threshold for filtering weak connections.\n",
    "    - color_factor: Factor to scale the visual weight.\n",
    "    \"\"\"\n",
    "\n",
    "    #ei = ei.cpu().numpy()\n",
    "    #ew = ew.cpu().numpy()\n",
    "    pq_path = 'data/PeakWeather/stations.parquet'\n",
    "    locations = pd.read_parquet(pq_path)\n",
    "    if 'index' in locations.columns:\n",
    "        locations = locations.set_index('index')\n",
    "    nodes_df = locations.loc[:, ['latitude', 'longitude']]\n",
    "\n",
    "    # Filter edges based on weight threshold\n",
    "    ei = nodes_df.index.to_numpy()[ei[:, ew > th]]\n",
    "    ew = ew[ew > th] * color_factor\n",
    "\n",
    "    # Create a map centered around the first coordinate\n",
    "    city_map = folium.Map(location=[nodes_df['latitude'].mean(), nodes_df['longitude'].mean()],\n",
    "                            zoom_start=12, tiles='Esri.WorldStreetMap', attr=\"Simplified Map\")\n",
    "\n",
    "\n",
    "    for i in range(ei.shape[1]):\n",
    "        # Get the coordinates of the start and end nodes\n",
    "        start_node = nodes_df.loc[nodes_df.index == ei[0, i]]\n",
    "        end_node = nodes_df.loc[nodes_df.index == ei[1, i]]\n",
    "        if len(start_node) == 0 or len(end_node) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            coords = [\n",
    "                [start_node['latitude'].values[0], start_node['longitude'].values[0]],\n",
    "                [end_node['latitude'].values[0], end_node['longitude'].values[0]]\n",
    "            ]\n",
    "            folium.PolyLine(coords, color=\"blue\", weight=float(ew[i]), opacity=float(ew[i])).add_to(city_map)\n",
    "\n",
    "    # Add points to the map\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        # folium.Marker(location=[row['latitude'], row['longitude']]).add_to(city_map)\n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=3,\n",
    "            color='orange',\n",
    "            fill=True,\n",
    "            fill_opacity=1,\n",
    "            popup=f\"Node {row.index}\"\n",
    "        ).add_to(city_map)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    city_map.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfee7d3",
   "metadata": {},
   "source": [
    "# Dataset - Only meteo stations (no rain gauges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696e5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import PeakWeather\n",
    "from tsl.data import SpatioTemporalDataset\n",
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "from tsl.data.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ade5f9",
   "metadata": {},
   "source": [
    "Here we compute the original adjacency matrix based on sensor distances.\n",
    "The weight between nodes i and j is given by:\n",
    "\n",
    "\\begin{split}\n",
    "w^{i,j} = \\left\\{\\begin{array}{cl}\n",
    "     \\exp \\left(-\\frac{\\operatorname{dist}\\left(i, j\\right)^{2}}{\\gamma}\\right) & \\operatorname{dist}\\left(i, j\\right) \\leq \\delta  \\\\\n",
    "     0 & \\text{otherwise}\n",
    "\\end{array}\\right. ,\n",
    "\\end{split}\n",
    "\n",
    "\n",
    "The function `dataset.get_connectivity()` computes this weighted connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897e6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PeakWeather(\n",
    "            root=\"data/v1\",\n",
    "            target_channels=[\"temperature\"],\n",
    "            covariate_channels=\"other\",\n",
    "            station_type=\"meteo_station\",\n",
    "            freq=\"h\",\n",
    "            extended_topo_vars=[\"DEM\", \"SLOPE_2000M_SIGRATIO1\"]) # elevation and slope\n",
    "connectivity = dataset.get_connectivity(layout=\"edge_index\",\n",
    "                                     include_self=False,\n",
    "                                     theta=50,\n",
    "                                     threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1cd1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has missing values: True\n",
      "Percentage of missing values: 7.09%\n",
      "Has Covariates: True\n",
      "Covariates: stations_table, installation_table, parameters_table, u, u_mask\n"
     ]
    }
   ],
   "source": [
    "print(f\"Has missing values: {dataset.has_mask}\")\n",
    "print(f\"Percentage of missing values: {(1 - dataset.mask.mean()) * 100:.2f}%\")\n",
    "print(f\"Has Covariates: {dataset.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset.covariates.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f36c483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <th>ABO</th>\n",
       "      <th>AEG</th>\n",
       "      <th>AIG</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AND</th>\n",
       "      <th>ANT</th>\n",
       "      <th>ARH</th>\n",
       "      <th>ARO</th>\n",
       "      <th>ATT</th>\n",
       "      <th>BAN</th>\n",
       "      <th>...</th>\n",
       "      <th>VAD</th>\n",
       "      <th>VEV</th>\n",
       "      <th>VIO</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VIT</th>\n",
       "      <th>VLS</th>\n",
       "      <th>WAE</th>\n",
       "      <th>WFJ</th>\n",
       "      <th>WYN</th>\n",
       "      <th>ZER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channels</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00+00:00</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>-7.20</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00+00:00</th>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>-10.40</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.80</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>-7.30</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>-3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00+00:00</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-10.30</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-7.30</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>-4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00+00:00</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-10.60</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.30</td>\n",
       "      <td>1.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-8.60</td>\n",
       "      <td>-7.30</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>-3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00+00:00</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-10.40</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-7.60</td>\n",
       "      <td>-7.30</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>-4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "nodes                             ABO         AEG         AIG         ALT  \\\n",
       "channels                  temperature temperature temperature temperature   \n",
       "datetime                                                                    \n",
       "2017-01-01 00:00:00+00:00        1.10        0.00       -4.70       -3.50   \n",
       "2017-01-01 01:00:00+00:00        1.60        0.00       -5.50       -3.60   \n",
       "2017-01-01 02:00:00+00:00        0.40        0.00       -5.90       -3.70   \n",
       "2017-01-01 03:00:00+00:00        1.10        0.00       -5.10       -3.80   \n",
       "2017-01-01 04:00:00+00:00        0.40        0.00       -6.00       -4.20   \n",
       "\n",
       "nodes                             AND         ANT         ARH         ARO  \\\n",
       "channels                  temperature temperature temperature temperature   \n",
       "datetime                                                                    \n",
       "2017-01-01 00:00:00+00:00       -6.20      -10.90       -3.70       -0.30   \n",
       "2017-01-01 01:00:00+00:00       -5.30      -10.40       -3.50        0.50   \n",
       "2017-01-01 02:00:00+00:00       -3.00      -10.30       -3.60       -0.40   \n",
       "2017-01-01 03:00:00+00:00       -4.00      -10.60       -3.10       -0.60   \n",
       "2017-01-01 04:00:00+00:00       -4.10      -10.40       -3.40       -0.50   \n",
       "\n",
       "nodes                             ATT         BAN  ...         VAD  \\\n",
       "channels                  temperature temperature  ... temperature   \n",
       "datetime                                           ...               \n",
       "2017-01-01 00:00:00+00:00       -3.50        0.00  ...       -5.80   \n",
       "2017-01-01 01:00:00+00:00       -3.00        0.00  ...       -6.70   \n",
       "2017-01-01 02:00:00+00:00       -3.70        0.00  ...       -6.90   \n",
       "2017-01-01 03:00:00+00:00       -2.90        0.00  ...       -7.30   \n",
       "2017-01-01 04:00:00+00:00       -3.40        0.00  ...       -7.40   \n",
       "\n",
       "nodes                             VEV         VIO         VIS         VIT  \\\n",
       "channels                  temperature temperature temperature temperature   \n",
       "datetime                                                                    \n",
       "2017-01-01 00:00:00+00:00        1.20        4.00       -8.40       -7.20   \n",
       "2017-01-01 01:00:00+00:00        1.20        3.80       -6.40       -7.30   \n",
       "2017-01-01 02:00:00+00:00        1.10        3.40       -7.90       -7.30   \n",
       "2017-01-01 03:00:00+00:00        1.10        3.00       -8.60       -7.30   \n",
       "2017-01-01 04:00:00+00:00        0.50        3.00       -7.60       -7.30   \n",
       "\n",
       "nodes                             VLS         WAE         WFJ         WYN  \\\n",
       "channels                  temperature temperature temperature temperature   \n",
       "datetime                                                                    \n",
       "2017-01-01 00:00:00+00:00       -5.00       -3.50       -3.20       -3.00   \n",
       "2017-01-01 01:00:00+00:00       -5.20       -3.40       -3.40       -3.20   \n",
       "2017-01-01 02:00:00+00:00       -5.40       -3.00       -3.60       -3.10   \n",
       "2017-01-01 03:00:00+00:00       -5.30       -3.30       -3.50       -3.20   \n",
       "2017-01-01 04:00:00+00:00       -5.60       -3.60       -3.80       -3.10   \n",
       "\n",
       "nodes                             ZER  \n",
       "channels                  temperature  \n",
       "datetime                               \n",
       "2017-01-01 00:00:00+00:00       -3.50  \n",
       "2017-01-01 01:00:00+00:00       -3.80  \n",
       "2017-01-01 02:00:00+00:00       -4.20  \n",
       "2017-01-01 03:00:00+00:00       -3.30  \n",
       "2017-01-01 04:00:00+00:00       -4.00  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002af0c",
   "metadata": {},
   "source": [
    "## plot interactive HTML map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638ffb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weight = connectivity\n",
    "plot_map(dataset, edge_index, edge_weight, 'peakweather_map.html', th=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805add6",
   "metadata": {},
   "source": [
    "### Transform to a pytorch compatible dataset (wrap with tsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5be6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataset(n_samples=36130, n_nodes=160, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=24,\n",
    "                                      window=6,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e46835",
   "metadata": {},
   "source": [
    "### Preparing the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89248335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using mean and std computed over time and node dimensions\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "#TODO split data based on date (test starts on 1st april 2024)\n",
    "splitter = TemporalSplitter(val_len=0.1, test_len=0.2)\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10dd9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Train dataloader: size=52022}\n",
      "{Validation dataloader: size=5774}\n",
      "{Test dataloader: size=14452}\n",
      "{Predict dataloader: None}\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup()\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741abf0",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb392fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from tsl.nn.blocks.encoders import RNN\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "class TimeThenSpaceModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 hidden_size: int = 32,\n",
    "                 rnn_layers: int = 1,\n",
    "                 gnn_kernel: int = 2):\n",
    "        super(TimeThenSpaceModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes, hidden_size)\n",
    "\n",
    "        self.time_nn = RNN(input_size=hidden_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           n_layers=rnn_layers,\n",
    "                           cell='gru',\n",
    "                           return_only_last_state=True)\n",
    "\n",
    "        self.space_nn = DiffConv(in_channels=hidden_size,\n",
    "                                 out_channels=hidden_size,\n",
    "                                 k=gnn_kernel)\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_size, input_size * horizon)\n",
    "        self.rearrange = Rearrange('b n (t f) -> b t n f', t=horizon)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [batch time nodes features]\n",
    "        x_enc = self.encoder(x)  # linear encoder: x_enc = xΘ + b\n",
    "        x_emb = x_enc + self.node_embeddings()  # add node-identifier embeddings\n",
    "        h = self.time_nn(x_emb)  # temporal processing: x=[b t n h] -> h=[b n h]\n",
    "        z = self.space_nn(h, edge_index, edge_weight)  # spatial processing\n",
    "        x_out = self.decoder(z)  # linear decoder: z=[b n h] -> x_out=[b n t⋅f]\n",
    "        x_horizon = self.rearrange(x_out) # x_out=[b n t⋅f] -> x_out=[b t n f]\n",
    "        return x_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c2e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeThenSpaceModel(\n",
      "  (encoder): Linear(in_features=1, out_features=32, bias=True)\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=160, embedding_size=32)\n",
      "  (time_nn): RNN(\n",
      "    (rnn): GRU(32, 32)\n",
      "  )\n",
      "  (space_nn): DiffConv(32, 32)\n",
      "  (decoder): Linear(in_features=32, out_features=24, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=24)\n",
      ")\n",
      "==========================================================\n",
      "Number of model (TimeThenSpaceModel) parameters:     17464\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 32   #@param\n",
    "rnn_layers = 1     #@param\n",
    "gnn_kernel = 2     #@param\n",
    "\n",
    "input_size = torch_dataset.n_channels   # 1 channel\n",
    "n_nodes = torch_dataset.n_nodes         # 207 nodes\n",
    "horizon = torch_dataset.horizon         # 12 time steps\n",
    "\n",
    "stgnn = TimeThenSpaceModel(input_size=input_size,\n",
    "                           n_nodes=n_nodes,\n",
    "                           horizon=horizon,\n",
    "                           hidden_size=hidden_size,\n",
    "                           rnn_layers=rnn_layers,\n",
    "                           gnn_kernel=gnn_kernel)\n",
    "print(stgnn)\n",
    "print_model_size(stgnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead602b9",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46331759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE(),\n",
    "           'mae_at_15': MaskedMAE(at=2),  # '2' indicates the third time step,\n",
    "                                          # which correspond to 3 hours ahead\n",
    "           'mae_at_30': MaskedMAE(at=5),\n",
    "           'mae_at_60': MaskedMAE(at=11)}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model=stgnn,                   # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': 0.001},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics                # metrics to be logged during train/val/test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b4257",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a513697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "# mlflow ui --port <PORT>\n",
    "logger = MLFlowLogger(experiment_name=\"temperature_prediction_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e7ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/miniconda3/envs/peakweather-env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /home/filippo/GitHub/peakweather-wind-forecasting/logs exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE          | 0      | train\n",
      "1 | train_metrics | MetricCollection   | 0      | train\n",
      "2 | val_metrics   | MetricCollection   | 0      | train\n",
      "3 | test_metrics  | MetricCollection   | 0      | train\n",
      "4 | model         | TimeThenSpaceModel | 17.5 K | train\n",
      "-------------------------------------------------------------\n",
      "17.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.5 K    Total params\n",
      "0.070     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/miniconda3/envs/peakweather-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "Only args ['edge_index', 'x', 'edge_weight'] are forwarded to the model (TimeThenSpaceModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/miniconda3/envs/peakweather-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 812/812 [00:05<00:00, 135.35it/s, v_num=062a, val_mae=1.920, val_mae_at_15=1.160, val_mae_at_30=1.830, val_mae_at_60=2.170, val_mape=1.36e+5, train_mae=1.930, train_mae_at_15=1.190, train_mae_at_30=1.890, train_mae_at_60=2.210, train_mape=1.36e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 812/812 [00:06<00:00, 135.22it/s, v_num=062a, val_mae=1.920, val_mae_at_15=1.160, val_mae_at_30=1.830, val_mae_at_60=2.170, val_mape=1.36e+5, train_mae=1.930, train_mae_at_15=1.190, train_mae_at_30=1.890, train_mae_at_60=2.210, train_mape=1.36e+5]\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     logger=logger,\n",
    "                     accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                     devices=1,\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef11727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/filippo/miniconda3/envs/peakweather-env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 226/226 [00:01<00:00, 203.66it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.9275665283203125\n",
      "        test_mae            1.9273463487625122\n",
      "     test_mae_at_15         1.1643688678741455\n",
      "     test_mae_at_30         1.8550270795822144\n",
      "     test_mae_at_60          2.211672306060791\n",
      "        test_mape              152778.953125\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "#predictor.load_model(checkpoint_callback.best_model_path)\n",
    "#predictor.freeze()\n",
    "trainer.test(predictor, datamodule=datamodule);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peakweather-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
